{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "mlRh0dzyTRo0",
        "Z5dtefRJQcWe",
        "ku0RDgjmQdmP",
        "xVQPqQvfiP_j",
        "uElMmvz9X1Px",
        "25lKSBgIXPR-",
        "mGSB_REEevdt"
      ],
      "gpuType": "A100",
      "machine_shape": "hm",
      "mount_file_id": "1b8T28SideCDC8dguTgl9iQyRjsqMTFv8",
      "authorship_tag": "ABX9TyOYFfaTQoWuwUFB7R5X5UW7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c2e482fb00934191970c6eab48aaa562": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_238b46f70f6149a9a3ccdb2cd1a3560c",
              "IPY_MODEL_009e59a03fad4cce91cebb6dc8fd5609",
              "IPY_MODEL_63d37c6a25674d59a719b13046fe1e1c",
              "IPY_MODEL_fe318f97fb9643608dccdfa4314a9561"
            ],
            "layout": "IPY_MODEL_d80f2e16a4774037af64cf0274c18907"
          }
        },
        "d9fb77b3fa964140a51f113f396952e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af27f1dbe9464a189b6281622982b155",
            "placeholder": "​",
            "style": "IPY_MODEL_a835a685f78646caab751e025d7305f2",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "9a348096199f48b484ab957d3ad38e69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_353d658f0c1448eba90e9c0df2e58543",
            "placeholder": "​",
            "style": "IPY_MODEL_83f70d9b31894912b86241608c04aee6",
            "value": ""
          }
        },
        "e34ecb0378ee48ff80ec8edd743a3167": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_dbe154da0de64d97a4eff8db97c0da43",
            "style": "IPY_MODEL_4bfe832b581140f5b78e9e5842b2483e",
            "value": true
          }
        },
        "26b1c3f2afeb47dea1c0609592b6bf72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_cbf82f6c3c224132bd279d268ff85ab2",
            "style": "IPY_MODEL_e2a5b4d09e9548cd8ea7c2ae190ff1df",
            "tooltip": ""
          }
        },
        "955cc3935a814faba045588fbdfdea96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16a014efb10645998ffc6b4a6324d0b3",
            "placeholder": "​",
            "style": "IPY_MODEL_a607f57066ea4a6ab113b41c3602ce2d",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "d80f2e16a4774037af64cf0274c18907": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "af27f1dbe9464a189b6281622982b155": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a835a685f78646caab751e025d7305f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "353d658f0c1448eba90e9c0df2e58543": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83f70d9b31894912b86241608c04aee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbe154da0de64d97a4eff8db97c0da43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bfe832b581140f5b78e9e5842b2483e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbf82f6c3c224132bd279d268ff85ab2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2a5b4d09e9548cd8ea7c2ae190ff1df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "16a014efb10645998ffc6b4a6324d0b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a607f57066ea4a6ab113b41c3602ce2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c476987ce874d3e95561c2984a99713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38f95aea141145f2b857491798c94711",
            "placeholder": "​",
            "style": "IPY_MODEL_1978a109c9b944f0a355f8e6f92ecfd6",
            "value": "Connecting..."
          }
        },
        "38f95aea141145f2b857491798c94711": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1978a109c9b944f0a355f8e6f92ecfd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "238b46f70f6149a9a3ccdb2cd1a3560c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42cf7f0363bf4712b4d424b8ad24155c",
            "placeholder": "​",
            "style": "IPY_MODEL_b055aa709cc34684955e7003001ada92",
            "value": "Token is valid (permission: write)."
          }
        },
        "009e59a03fad4cce91cebb6dc8fd5609": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e11f208fdebc462e93ac59fa925b3cf7",
            "placeholder": "​",
            "style": "IPY_MODEL_57292c5212424477b75afd4881286ad7",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "63d37c6a25674d59a719b13046fe1e1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15138310983940bd9e12773b374e21f1",
            "placeholder": "​",
            "style": "IPY_MODEL_8624d07f0b2548c081e9cf97961aba62",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "fe318f97fb9643608dccdfa4314a9561": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cacfa0757cb4320810ee9cf54ffd882",
            "placeholder": "​",
            "style": "IPY_MODEL_dacafb24135a4828ba6b3f632fb0fce8",
            "value": "Login successful"
          }
        },
        "42cf7f0363bf4712b4d424b8ad24155c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b055aa709cc34684955e7003001ada92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e11f208fdebc462e93ac59fa925b3cf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57292c5212424477b75afd4881286ad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15138310983940bd9e12773b374e21f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8624d07f0b2548c081e9cf97961aba62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9cacfa0757cb4320810ee9cf54ffd882": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dacafb24135a4828ba6b3f632fb0fce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f00b44bc76e4185b8f84247c4fd2426": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9498c248f44f4cc4bd25441e53a4226f",
              "IPY_MODEL_c6f9a24e70334daebf0a0cebc2ec94af",
              "IPY_MODEL_4d37888e063c4adea6598cfca6ebb2f9"
            ],
            "layout": "IPY_MODEL_9ed763620d294e7d8528d99b0767dc04"
          }
        },
        "9498c248f44f4cc4bd25441e53a4226f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d864fc54c094e908781b35675c32be2",
            "placeholder": "​",
            "style": "IPY_MODEL_7f35c2861d99484aa33262e4f215990b",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "c6f9a24e70334daebf0a0cebc2ec94af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2c1491b0a2b49e8918ea4d5a9957a9d",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d569458da66f4efbbd8cc2b5555a6b56",
            "value": 2
          }
        },
        "4d37888e063c4adea6598cfca6ebb2f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7abd4481af664acb9fe9840e03023a79",
            "placeholder": "​",
            "style": "IPY_MODEL_03c7faf84c4e4c4eb9eed8d1e4fc6311",
            "value": " 2/2 [00:04&lt;00:00,  2.01s/it]"
          }
        },
        "9ed763620d294e7d8528d99b0767dc04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d864fc54c094e908781b35675c32be2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f35c2861d99484aa33262e4f215990b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2c1491b0a2b49e8918ea4d5a9957a9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d569458da66f4efbbd8cc2b5555a6b56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7abd4481af664acb9fe9840e03023a79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03c7faf84c4e4c4eb9eed8d1e4fc6311": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/david-meltzer/LLMs/blob/main/training/SFT_QA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependencies"
      ],
      "metadata": {
        "id": "mlRh0dzyTRo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/LLMs/Fine-tuning/SFT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ms8_xmoajbsF",
        "outputId": "597efc98-aab5-4f54-9156-8414d0459110"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/LLMs/Fine-tuning/SFT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8B42jKAnRLXR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2bf70e8-c7f6-4040-ced7-468368d86d9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: peft==0.4.0 in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0) (4.31.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0) (0.21.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0) (0.3.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.0->peft==0.4.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.0->peft==0.4.0) (16.0.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.4.0) (0.16.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.4.0) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.4.0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.4.0) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.4.0) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers->peft==0.4.0) (2023.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft==0.4.0) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft==0.4.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft==0.4.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft==0.4.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft==0.4.0) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft==0.4.0) (1.3.0)\n",
            "Requirement already satisfied: accelerate==0.21.0 in /usr/local/lib/python3.10/dist-packages (0.21.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate==0.21.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate==0.21.0) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.21.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.21.0) (1.3.0)\n",
            "Requirement already satisfied: bitsandbytes==0.40.2 in /usr/local/lib/python3.10/dist-packages (0.40.2)\n",
            "Requirement already satisfied: trl in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from trl) (2.0.1+cu118)\n",
            "Requirement already satisfied: transformers>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from trl) (4.31.0)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.10/dist-packages (from trl) (1.23.5)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from trl) (0.21.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from trl) (2.14.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4.0->trl) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4.0->trl) (16.0.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl) (0.16.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl) (0.3.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.18.0->trl) (4.65.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->trl) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (3.3.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (3.8.5)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.18.0->trl) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.18.0->trl) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.18.0->trl) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->trl) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2022.7.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets->trl) (1.16.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.15.8)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.6)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.32)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.29.2)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.10/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n"
          ]
        }
      ],
      "source": [
        "# installations\n",
        "\n",
        "!pip install -U transformers\n",
        "!pip install peft==0.4.0\n",
        "!pip install accelerate==0.21.0\n",
        "!pip install bitsandbytes==0.40.2\n",
        "!pip install safetensors>=0.3.1\n",
        "!pip install tokenizers>=0.13.3\n",
        "!pip install trl\n",
        "!pip install wandb\n",
        "\n",
        "#!pip install transformers -qqq\n",
        "#!pip install datasets --upgrade -qqq\n",
        "#!pip install apache-beam -qqq\n",
        "#!pip install wandb -qqq\n",
        "#!pip install accelerate -qqq\n",
        "#!pip install trl -qqq\n",
        "#!pip install bitsandbytes -qqq\n",
        "#!pip install peft -qqq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from google.colab import runtime\n",
        "import pandas as pd\n",
        "\n",
        "import datasets\n",
        "import accelerate\n",
        "import transformers\n",
        "from transformers import (AutoTokenizer,\n",
        "                          AutoModelForCausalLM,\n",
        "                          Trainer,\n",
        "                          TrainingArguments,\n",
        "                          DataCollatorForLanguageModeling,\n",
        "                          BitsAndBytesConfig,\n",
        "                          TrainerCallback)\n",
        "import bitsandbytes as bnb\n",
        "import wandb\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
        "from datetime import datetime\n",
        "from huggingface_hub import login\n",
        "\n",
        "from peft.tuners.lora import LoraLayer"
      ],
      "metadata": {
        "id": "SetPqPtmTEYf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()\n",
        "login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162,
          "referenced_widgets": [
            "c2e482fb00934191970c6eab48aaa562",
            "d9fb77b3fa964140a51f113f396952e2",
            "9a348096199f48b484ab957d3ad38e69",
            "e34ecb0378ee48ff80ec8edd743a3167",
            "26b1c3f2afeb47dea1c0609592b6bf72",
            "955cc3935a814faba045588fbdfdea96",
            "d80f2e16a4774037af64cf0274c18907",
            "af27f1dbe9464a189b6281622982b155",
            "a835a685f78646caab751e025d7305f2",
            "353d658f0c1448eba90e9c0df2e58543",
            "83f70d9b31894912b86241608c04aee6",
            "dbe154da0de64d97a4eff8db97c0da43",
            "4bfe832b581140f5b78e9e5842b2483e",
            "cbf82f6c3c224132bd279d268ff85ab2",
            "e2a5b4d09e9548cd8ea7c2ae190ff1df",
            "16a014efb10645998ffc6b4a6324d0b3",
            "a607f57066ea4a6ab113b41c3602ce2d",
            "9c476987ce874d3e95561c2984a99713",
            "38f95aea141145f2b857491798c94711",
            "1978a109c9b944f0a355f8e6f92ecfd6",
            "238b46f70f6149a9a3ccdb2cd1a3560c",
            "009e59a03fad4cce91cebb6dc8fd5609",
            "63d37c6a25674d59a719b13046fe1e1c",
            "fe318f97fb9643608dccdfa4314a9561",
            "42cf7f0363bf4712b4d424b8ad24155c",
            "b055aa709cc34684955e7003001ada92",
            "e11f208fdebc462e93ac59fa925b3cf7",
            "57292c5212424477b75afd4881286ad7",
            "15138310983940bd9e12773b374e21f1",
            "8624d07f0b2548c081e9cf97961aba62",
            "9cacfa0757cb4320810ee9cf54ffd882",
            "dacafb24135a4828ba6b3f632fb0fce8"
          ]
        },
        "id": "8Al1Jp6GUbZu",
        "outputId": "080cbd47-38be-454e-a840-a391c176151f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdmeltzer\u001b[0m (\u001b[33mft-llmmm\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c2e482fb00934191970c6eab48aaa562"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definitions"
      ],
      "metadata": {
        "id": "Gjygy89vQITv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datasets"
      ],
      "metadata": {
        "id": "Z5dtefRJQcWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setup collator\n",
        "\n",
        "\n",
        "def formatting_prompts_func(example):\n",
        "    output_texts = []\n",
        "    for i in range(len(example['question'])):\n",
        "        text = f\"### Question: {example['question'][i]}\\n ### Answer: {example['answer'][i]}\"\n",
        "        output_texts.append(text)\n",
        "    return output_texts\n",
        "\n",
        "def sft_collator(tokenizer, response_template = \" ### Answer:\"):\n",
        "\n",
        "    return DataCollatorForCompletionOnlyLM(response_template=response_template, tokenizer=tokenizer)\n",
        "\n",
        "\n",
        "\n",
        "#def formatting_prompts_func(example):\n",
        "#    output_texts = []\n",
        "#    for i in range(len(example['question'])):\n",
        "#        text = f\"### Question: {example['question'][i]}\\n\\n### Answer: {example['answer'][i]}\"\n",
        "#        output_texts.append(text)\n",
        "#    return output_texts\n",
        "#response_template = \" ### Answer:\"\n",
        "#sft_collator = DataCollatorForCompletionOnlyLM(response_template=response_template, tokenizer=tokenizer)\n",
        "\n",
        "#def sft_collator(tokenizer, response_template = \"\\n\\n### Answer:\"):\n",
        "#    return DataCollatorForCompletionOnlyLM(response_template=response_template, tokenizer=tokenizer)\n",
        "\n",
        "def combine_question_answer(ds,formatting_func):\n",
        "\n",
        "    if 'QA' not in ds['train']:\n",
        "        ds = ds.map(lambda x: {'QA':formatting_func(x)},\n",
        "                    batched=True)\n",
        "    return ds\n",
        "\n",
        "def prepare_dataset(ds,\n",
        "                    tokenizer,\n",
        "                    formatting_func,\n",
        "                    max_seq_length='auto'):\n",
        "\n",
        "    if max_seq_length == 'auto':\n",
        "        max_seq_length = tokenizer.model_max_length\n",
        "\n",
        "    ds = combine_question_answer(ds,formatting_func)\n",
        "\n",
        "    ds = ds.map(lambda x: {'tokens':tokenizer(x['QA'],\n",
        "                                              return_length=False)})\n",
        "\n",
        "    ds = ds.filter(lambda x: len(x['tokens']['input_ids'])<=max_seq_length)\n",
        "\n",
        "    return ds"
      ],
      "metadata": {
        "id": "nE0Vqvn1QiX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "ku0RDgjmQdmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PeftSavingCallback(TrainerCallback):\n",
        "    def on_save(self, args, state, control, **kwargs):\n",
        "        checkpoint_path = os.path.join(args.output_dir, f\"checkpoint-{state.global_step}\")\n",
        "        kwargs[\"model\"].save_pretrained(checkpoint_path)\n",
        "\n",
        "        if \"pytorch_model.bin\" in os.listdir(checkpoint_path):\n",
        "            os.remove(os.path.join(checkpoint_path, \"pytorch_model.bin\"))\n",
        "\n",
        "def prepare_model(checkpoint,\n",
        "                 target_modules,\n",
        "                 lora_rank=32,\n",
        "                 lora_alpha=32,\n",
        "                 lora_dropout=0.05,\n",
        "                 bias=\"none\",\n",
        "                 task_type=\"CAUSAL_LM\",\n",
        "                 model_type = 'qlora',\n",
        "                 extra_quant = True):\n",
        "\n",
        "    if model_type not in {'lora','qlora','full'}:\n",
        "        raise ValueError('Train type should be \"lora\", \"qlora\", or \"full\".')\n",
        "\n",
        "    if model_type in {'lora','qlora'}:\n",
        "\n",
        "        if model_type == 'qlora':\n",
        "\n",
        "            nf4_config = BitsAndBytesConfig(load_in_4bit=True,\n",
        "                                    bnb_4bit_quant_type=\"nf4\",\n",
        "                                    bnb_4bit_use_double_quant = extra_quant,\n",
        "                                    bnb_4bit_compute_dtype=torch.bfloat16\n",
        "                                    )\n",
        "\n",
        "            model = AutoModelForCausalLM.from_pretrained(checkpoint,\n",
        "                                                quantization_config=nf4_config,\n",
        "                                                device_map='auto',\n",
        "                                                torch_dtype = torch.bfloat16\n",
        "                                                )\n",
        "        else:\n",
        "            model = AutoModelForCausalLM.from_pretrained(checkpoint,\n",
        "                                                 load_in_8bit = extra_quant)\n",
        "\n",
        "        model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "        lora_config = LoraConfig(\n",
        "          r = lora_rank,\n",
        "          lora_alpha = lora_alpha,\n",
        "          target_modules = target_modules,\n",
        "          lora_dropout = lora_dropout,\n",
        "          bias = bias,\n",
        "          task_type = task_type\n",
        "          )\n",
        "\n",
        "        model = get_peft_model(model, lora_config)\n",
        "    else:\n",
        "        model = AutoModelForCausalLM.from_pretrained(checkpoint)\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    model_name = checkpoint.split('/')[-1]\n",
        "\n",
        "    if model_type in {'lora','qlora'}:\n",
        "        model_name += f'_{model_type}'\n",
        "        model_name += f'_r_{lora_rank}_a_{lora_alpha}'\n",
        "\n",
        "    return model, tokenizer, model_name\n",
        "\n",
        "\n",
        "def prepare_hyperparameters(model_name,\n",
        "                            ds_name,\n",
        "                            evaluation_strategy = 'steps',\n",
        "                            save_steps = .1,\n",
        "                            eval_steps = .1,\n",
        "                            logging_steps = 100,\n",
        "                            log_level = 'error',\n",
        "                            report_to = 'wandb',\n",
        "                            num_train_epochs = 3,\n",
        "                            lr = 5e-5,\n",
        "                            warmup_steps = 50,\n",
        "                            weight_decay = .01,\n",
        "                            optim = 'adamw_torch_fused',\n",
        "                            prec = 'fp16',\n",
        "                            train_batch_size = 8,\n",
        "                            eval_batch_size = 16,\n",
        "                            grad_accum = 4,\n",
        "                            grad_checkpoint = True,\n",
        "                            group_by_length = True,\n",
        "                            dataloader_num_workers = 2,\n",
        "                            save_total_limit = 3):\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        logging_dir = f'./{model_name}_{ds_name}/logs',\n",
        "        output_dir= f'./{model_name}_{ds_name}/models',\n",
        "        evaluation_strategy = evaluation_strategy,\n",
        "        save_strategy = evaluation_strategy,\n",
        "        save_steps = save_steps,\n",
        "        eval_steps = eval_steps,\n",
        "        logging_steps = logging_steps,\n",
        "        log_level = log_level,\n",
        "        report_to = report_to,\n",
        "        num_train_epochs = num_train_epochs,\n",
        "        learning_rate = lr,\n",
        "        warmup_steps = warmup_steps,\n",
        "        weight_decay = weight_decay,\n",
        "        optim = optim,\n",
        "        fp16 = True if prec=='fp16' else False,\n",
        "        bf16 = True if prec=='bf16' else False,\n",
        "        per_device_train_batch_size = train_batch_size,\n",
        "        per_device_eval_batch_size = eval_batch_size,\n",
        "        gradient_accumulation_steps = grad_accum,\n",
        "        gradient_checkpointing = grad_checkpoint,\n",
        "        group_by_length = group_by_length,\n",
        "        dataloader_num_workers = dataloader_num_workers,\n",
        "        load_best_model_at_end=True,\n",
        "        save_total_limit = save_total_limit,\n",
        "        )\n",
        "\n",
        "    if report_to == 'wandb':\n",
        "\n",
        "        %env WANDB_PROJECT = 'SFT_training_dm'\n",
        "\n",
        "        now = datetime.now()\n",
        "        time_stamp = now.strftime(\"%m.%d.%y-%H.%M.%S\")\n",
        "\n",
        "        run_name = f'{model_name}__time_stamp'\n",
        "\n",
        "        training_args.run_name = run_name\n",
        "\n",
        "\n",
        "\n",
        "    return training_args\n",
        "\n",
        "def SFT_train(model,\n",
        "              tokenizer,\n",
        "              training_args,\n",
        "              dataset,\n",
        "              ds_name,\n",
        "              dataset_text_field='QA',\n",
        "              formatting_func = formatting_prompts_func,\n",
        "              max_seq_length = 'auto',\n",
        "              packing = False,\n",
        "              collator = sft_collator,\n",
        "              preprocess_ds = False\n",
        "              ):\n",
        "\n",
        "    if max_seq_length == 'auto':\n",
        "        max_seq_length = tokenizer.model_max_length\n",
        "\n",
        "    if training_args.gradient_checkpointing:\n",
        "        model.gradient_checkpointing_enable()\n",
        "\n",
        "    if not packing:\n",
        "        collator = collator(tokenizer)\n",
        "\n",
        "    if ds_name == 'ELI5':\n",
        "        dataset = dataset.filter(lambda x:x['source']=='ELI5')\n",
        "    elif ds_name == 'simple_wiki':\n",
        "        dataset = dataset.filter(lambda x:x['source']=='simple_wiki')\n",
        "\n",
        "    if preprocess_ds:\n",
        "\n",
        "        dataset = prepare_dataset(dataset,tokenizer,formatting_func)\n",
        "\n",
        "    sft_trainer = SFTTrainer(\n",
        "            model,\n",
        "            training_args,\n",
        "            max_seq_length=max_seq_length,\n",
        "            train_dataset=dataset['train'],\n",
        "            eval_dataset=dataset['validation'],\n",
        "            dataset_text_field=dataset_text_field,\n",
        "            data_collator=collator if not packing else None,\n",
        "            callbacks=[PeftSavingCallback()],\n",
        "            packing=packing\n",
        "            )\n",
        "\n",
        "    sft_trainer.train()\n",
        "\n",
        "    wandb.finish()\n",
        "\n",
        "def full_training(\n",
        "    checkpoint,\n",
        "    dataset,\n",
        "    ds_name,\n",
        "    target_modules=None,\n",
        "    dataset_text_field=\"QA\",\n",
        "    max_seq_length = 'auto',\n",
        "    lora_rank=32,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    model_type = 'qlora',\n",
        "    extra_quant = True,\n",
        "    evaluation_strategy = 'steps',\n",
        "    save_steps = 0.1,\n",
        "    eval_steps = 0.1,\n",
        "    logging_steps = 100,\n",
        "    log_level = 'error',\n",
        "    report_to = 'wandb',\n",
        "    num_train_epochs = 3,\n",
        "    lr = 5e-5,\n",
        "    warmup_steps = 50,\n",
        "    weight_decay = .01,\n",
        "    optim = 'adamw_torch_fused',\n",
        "    prec = 'fp16',\n",
        "    train_batch_size = 8,\n",
        "    eval_batch_size = 16,\n",
        "    grad_accum = 4,\n",
        "    grad_checkpoint = True,\n",
        "    group_by_length = True,\n",
        "    dataloader_num_workers = 2,\n",
        "    save_total_limit = 3,\n",
        "    wandb_report = 'SFT_training_dm',\n",
        "    packing = False,\n",
        "    collator = sft_collator,\n",
        "    preprocess_ds = False\n",
        "    ):\n",
        "\n",
        "    model, tokenizer, model_name = prepare_model(checkpoint,\n",
        "                                                 target_modules,\n",
        "                                                lora_rank=lora_rank,\n",
        "                                                lora_alpha=lora_alpha,\n",
        "                                                lora_dropout=lora_dropout,\n",
        "                                                bias=bias,\n",
        "                                                task_type=task_type,\n",
        "                                                model_type = model_type,\n",
        "                                                extra_quant = extra_quant)\n",
        "\n",
        "    training_args = prepare_hyperparameters(model_name,\n",
        "                            ds_name,\n",
        "                            evaluation_strategy =evaluation_strategy,\n",
        "                            save_steps = save_steps,\n",
        "                            eval_steps = eval_steps,\n",
        "                            logging_steps = logging_steps,\n",
        "                            log_level = log_level,\n",
        "                            report_to = report_to,\n",
        "                            num_train_epochs = num_train_epochs,\n",
        "                            lr = lr,\n",
        "                            warmup_steps = warmup_steps,\n",
        "                            weight_decay = weight_decay,\n",
        "                            optim = optim,\n",
        "                            prec = prec,\n",
        "                            train_batch_size = train_batch_size,\n",
        "                            eval_batch_size = eval_batch_size,\n",
        "                            grad_accum = grad_accum,\n",
        "                            grad_checkpoint = grad_checkpoint,\n",
        "                            group_by_length = group_by_length,\n",
        "                            dataloader_num_workers = dataloader_num_workers,\n",
        "                            save_total_limit = save_total_limit,\n",
        "                            wandb_report = wandb_report\n",
        "                            )\n",
        "\n",
        "    SFT_train(model,\n",
        "              tokenizer,\n",
        "              training_args,\n",
        "              dataset = dataset,\n",
        "              dataset_text_field=dataset_text_field,\n",
        "              ds_name = ds_name,\n",
        "              max_seq_length = max_seq_length,\n",
        "              packing = packing,\n",
        "              collator = collator,\n",
        "              preprocess_ds = preprocess_ds\n",
        "              )\n",
        "\n"
      ],
      "metadata": {
        "id": "V_AiKvwlQafD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets"
      ],
      "metadata": {
        "id": "xVQPqQvfiP_j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download and Combine Datasets"
      ],
      "metadata": {
        "id": "UvhKLq9bXygs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#with wandb.init(project='ELI5_analysis',\n",
        "#                 entity='ft-llmmm',\n",
        "#                 job_type='training',\n",
        "#                 name='SFT_training') as run:\n",
        "#\n",
        "#    artifact_wiki_QA = run.use_artifact('ft-llmmm/ELI5_analysis/simple_wiki_QA:v1', type='dataset')\n",
        "#    artifact_dir_wiki_QA = artifact_wiki_QA.download()\n",
        "#\n",
        "#    artifact_ELI5 = run.use_artifact('ft-llmmm/ELI5_analysis/ELI5_cleaned:v2', type='dataset')\n",
        "#    artifact_dir_ELI5 = artifact_ELI5.download()"
      ],
      "metadata": {
        "id": "PuVdhm5MigZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "artifact_dir_wiki_QA='./artifacts/simple_wiki_QA:v1'\n",
        "artifact_dir_ELI5='./artifacts/ELI5_cleaned:v2'"
      ],
      "metadata": {
        "id": "HSJNQ4UEqzmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simplewiki_QA_ds = datasets.load_dataset(\"csv\",\n",
        "                                         data_files={\"train\": artifact_dir_wiki_QA + '/simple_wiki_QA_combined_train.csv',\n",
        "                                                    \"test\": artifact_dir_wiki_QA +  '/simple_wiki_QA_combined_test.csv',\n",
        "                                                    \"val\": artifact_dir_wiki_QA + '/simple_wiki_QA_combined_validation.csv'\n",
        "                                        }\n",
        ")\n",
        "simplewiki_QA_ds = simplewiki_QA_ds.remove_columns(['id','system_message','prompt_template'])\n",
        "simplewiki_QA_ds = simplewiki_QA_ds.rename_columns({'trunc_text':'answer'})\n",
        "\n",
        "simplewiki_QA_ds['validation'] = simplewiki_QA_ds['val']\n",
        "del simplewiki_QA_ds['val']"
      ],
      "metadata": {
        "id": "3NygRQl1mbCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for split in simplewiki_QA_ds:\n",
        "    dset_source = datasets.Dataset.from_dict({'source':['simple_wiki']*len(simplewiki_QA_ds[split])})\n",
        "    simplewiki_QA_ds[split] = datasets.concatenate_datasets([simplewiki_QA_ds[split],dset_source],axis=1)"
      ],
      "metadata": {
        "id": "Y0urp2yuZ8DU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ELI5_ds = datasets.load_from_disk(f'{artifact_dir_ELI5}/ds_SFT')\n",
        "ELI5_ds = ELI5_ds.flatten()\n",
        "ELI5_ds = ELI5_ds.remove_columns(['document','q_id','title','selftext','subreddit','url','title_urls','selftext_urls','answers_urls','pref_idxs','dupl_scores_idxs','qu_emb',\n",
        "                                  'answers.a_id','answers.fkg','answers.fre', 'answers.score'])\n",
        "ELI5_ds = ELI5_ds.map(lambda x: {'answers.text':list(x['answers.text'])})\n",
        "\n",
        "ELI5_ds = ELI5_ds.with_format(\"pandas\").map(lambda df:\n",
        "                                                df.explode(\"answers.text\"),\n",
        "                                                batched=True)\n",
        "\n",
        "ELI5_ds = ELI5_ds.with_format(None)\n",
        "\n",
        "ELI5_ds = ELI5_ds.remove_columns(['__index_level_0__'])\n",
        "ELI5_ds = ELI5_ds.rename_columns({'answers.text':'answer',\n",
        "                                  'title_body':'question'})"
      ],
      "metadata": {
        "id": "S3cTYfeZqsfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for split in ELI5_ds:\n",
        "    dset_source = datasets.Dataset.from_dict({'source':['ELI5']*len(ELI5_ds[split])})\n",
        "    ELI5_ds[split] = datasets.concatenate_datasets([ELI5_ds[split],dset_source],axis=1)"
      ],
      "metadata": {
        "id": "S7-r3wefZhuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SFT_QA_dataset = datasets.DatasetDict()\n",
        "\n",
        "for split in ['train','validation','test']:\n",
        "\n",
        "    SFT_QA_dataset[split] = datasets.concatenate_datasets([simplewiki_QA_ds[split],\n",
        "                                                ELI5_ds[split]])"
      ],
      "metadata": {
        "id": "uLRl5bK_xGms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SFT_QA_dataset = SFT_QA_dataset.shuffle(seed=12321)"
      ],
      "metadata": {
        "id": "ADDaYMxLx0Ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SFT_QA_dataset = combine_question_answer(SFT_QA_dataset,formatting_prompts_func)"
      ],
      "metadata": {
        "id": "KnyY6bR_qVhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SFT_QA_dataset.save_to_disk('./data/SFT_QA_ds')"
      ],
      "metadata": {
        "id": "2yOpZHqoyUJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "now = datetime.now()\n",
        "time_stamp = now.strftime(\"%m.%d.%y-%H.%M.%S\")\n",
        "with wandb.init(project='ELI5_analysis',\n",
        "                entity='ft-llmmm',\n",
        "                job_type='upload_data',\n",
        "                name=f'combined_dataset_{time_stamp}') as run:\n",
        "\n",
        "    clean_data_art = wandb.Artifact('combined_dataset', 'dataset')\n",
        "    clean_data_art.add_dir('./data/SFT_QA_ds')\n",
        "    run.log_artifact(clean_data_art)"
      ],
      "metadata": {
        "id": "cNMSSkDzbGqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instruction Formatting"
      ],
      "metadata": {
        "id": "uElMmvz9X1Px"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tok = AutoTokenizer.from_pretrained('distilgpt2')\n",
        "GPT2_QA_tokenized = prepare_dataset(SFT_QA_dataset,tok,formatting_prompts_func)\n",
        "GPT2_QA_tokenized.save_to_disk('./data/GPT2_QA_tokenized')\n",
        "\n",
        "#now = datetime.now()\n",
        "#time_stamp = now.strftime(\"%m.%d.%y-%H.%M.%S\")\n",
        "#with wandb.init(project='ELI5_analysis',\n",
        "#                entity='ft-llmmm',\n",
        "#                job_type='upload_data',\n",
        "#                name=f'GPT2_QA_tokenized_dataset_{time_stamp}') as run:\n",
        "#\n",
        "#    clean_data_art = wandb.Artifact('GPT2_QA_tokenized', 'dataset')\n",
        "#    clean_data_art.add_dir('./data/GPT2_QA_tokenized')\n",
        "#    run.log_artifact(clean_data_art)"
      ],
      "metadata": {
        "id": "BNmO8W7TcT5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Llama"
      ],
      "metadata": {
        "id": "z8vKqVttfDWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SFT_QA_dataset = datasets.load_from_disk('../data/SFT_QA_ds')\n",
        "\n",
        "ds_wiki = SFT_QA_dataset.filter(lambda x:\n",
        "                                x['source']=='simple_wiki')"
      ],
      "metadata": {
        "id": "QX9iI0-w4KnA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_wiki=ds_wiki.remove_columns(['source','QA'])"
      ],
      "metadata": {
        "id": "n0LIlzsfHvbb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"meta-llama/Llama-2-7b-hf\" # sharded weights\n",
        "model_name = model_id.split('/')[-1]\n",
        "llama_tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "llama_tokenizer.pad_token = llama_tokenizer.eos_token"
      ],
      "metadata": {
        "id": "eCBrHYIIqhBR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%env WANDB_LOG_MODEL='end'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0jXdchp5kKM",
        "outputId": "009b344b-a9fc-48fd-fac0-6adf78318169"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: WANDB_LOG_MODEL='end'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_all_linear_names(model):\n",
        "    lora_module_names = set()\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, bnb.nn.Linear4bit):\n",
        "            names = name.split(\".\")\n",
        "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
        "\n",
        "    if \"lm_head\" in lora_module_names:  # needed for 16-bit\n",
        "        lora_module_names.remove(\"lm_head\")\n",
        "    return list(lora_module_names)\n",
        "\n",
        "def create_peft_model(model,\n",
        "                      r=64,\n",
        "                      lora_alpha=16,\n",
        "                      lora_dropout=0.1,\n",
        "                      bias='none',\n",
        "                      task_type='CAUSAL_LM',\n",
        "                      gradient_checkpointing=True,\n",
        "                      bf16=True):\n",
        "\n",
        "    # prepare int-4 model for training\n",
        "    model = prepare_model_for_kbit_training(\n",
        "        model, use_gradient_checkpointing=gradient_checkpointing\n",
        "    )\n",
        "    if gradient_checkpointing:\n",
        "        model.gradient_checkpointing_enable()\n",
        "\n",
        "    # get lora target modules\n",
        "    modules = find_all_linear_names(model)\n",
        "    print(f\"Found {len(modules)} modules to quantize: {modules}\")\n",
        "\n",
        "    peft_config = LoraConfig(\n",
        "        r=r,\n",
        "        lora_alpha=lora_alpha,\n",
        "        target_modules=modules,\n",
        "        lora_dropout=lora_dropout,\n",
        "        bias=bias,\n",
        "        task_type=task_type,\n",
        "    )\n",
        "\n",
        "    model = get_peft_model(model, peft_config)\n",
        "\n",
        "    # pre-process the model by upcasting the layer norms in float 32 for\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, LoraLayer):\n",
        "            if bf16:\n",
        "                module = module.to(torch.bfloat16)\n",
        "        if \"norm\" in name:\n",
        "            module = module.to(torch.float32)\n",
        "        if \"lm_head\" in name or \"embed_tokens\" in name:\n",
        "            if hasattr(module, \"weight\"):\n",
        "                if bf16 and module.weight.dtype == torch.float32:\n",
        "                    module = module.to(torch.bfloat16)\n",
        "\n",
        "    model.print_trainable_parameters()\n",
        "    return model\n",
        "\n",
        "def formatting_prompts_func(example):\n",
        "    output_texts = []\n",
        "    for i in range(len(example['question'])):\n",
        "        text = f\"### Question: {example['question'][i]}\\n ### Answer: {example['answer'][i]}\"\n",
        "        output_texts.append(text)\n",
        "    return output_texts\n",
        "\n",
        "def sft_collator(tokenizer, response_template = \"### Answer:\"):\n",
        "    return DataCollatorForCompletionOnlyLM(response_template=response_template, tokenizer=tokenizer)\n",
        "\n",
        "def training_function(model_id,\n",
        "                      dataset,\n",
        "                      hf_token,\n",
        "                      wandb_token,\n",
        "                      ds_name,\n",
        "                      r=64,\n",
        "                      lora_alpha=16,\n",
        "                      lora_dropout=0.1,\n",
        "                      bias='none',\n",
        "                      task_type='CAUSAL_LM',\n",
        "                      max_seq_length=512,\n",
        "                      epochs = 1,\n",
        "                      max_steps = -1,\n",
        "                      gradient_checkpointing = True,\n",
        "                      lr=2e-4,\n",
        "                      weight_decay=.01,\n",
        "                      per_device_train_batch_size=16,\n",
        "                      per_device_eval_batch_size=16,\n",
        "                      gradient_accumulation_steps=4,\n",
        "                      optim='paged_adamw_32bit',\n",
        "                      warmup_ratio=0.03,\n",
        "                      group_by_length=True,\n",
        "                      dataloader_num_workers=2,\n",
        "                      logging_steps=10,\n",
        "                      save_total_limit=3,\n",
        "                      save_strategy='steps',\n",
        "                      save_steps =.2,\n",
        "                      eval_steps=.2,\n",
        "                      load_best_model_at_end=True,\n",
        "                      project_name='SFT_training_dm',\n",
        "                      entity='ft-llmmm'):\n",
        "    # set seed\n",
        "\n",
        "    now = datetime.now()\n",
        "    time_stamp = now.strftime(\"%m.%d.%y-%H.%M.%S\")\n",
        "\n",
        "    model_name = model_id.split('/')[-1]\n",
        "    model_name = f'{model_name}_{ds_name}_r_{r}_alpha_{lora_alpha}'\n",
        "\n",
        "    run_name = f'{model_name}_{time_stamp}'\n",
        "\n",
        "    if torch.cuda.get_device_capability()[0] == 8:\n",
        "        bf16=True,\n",
        "        fp16=False\n",
        "    else:\n",
        "        bf16=False\n",
        "        fp16=True\n",
        "\n",
        "    #dataset = datasets.load_from_disk(args.dataset_path)\n",
        "    # load model from the hub with a bnb config\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    )\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_id,\n",
        "        use_cache=False\n",
        "        if gradient_checkpointing\n",
        "        else True,  # this is needed for gradient checkpointing\n",
        "        device_map=\"auto\",\n",
        "        quantization_config=bnb_config,\n",
        "        #use_auth_token=hf_token\n",
        "    )\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\n",
        "        model_id,\n",
        "        use_auth_token=hf_token\n",
        "    )\n",
        "\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    model = create_peft_model(model,\n",
        "                      r=r,\n",
        "                      lora_alpha=lora_alpha,\n",
        "                      lora_dropout=lora_dropout,\n",
        "                      bias=bias,\n",
        "                      task_type=task_type,\n",
        "                      gradient_checkpointing=gradient_checkpointing,\n",
        "                      bf16=bf16)\n",
        "\n",
        "    with wandb.init(project='SFT_Training_dm',\n",
        "                 entity='ft-llmmm',\n",
        "                 job_type='SFT_training',\n",
        "                 name=run_name) as run:\n",
        "\n",
        "        output_dir = f'./{model_name}_{ds_name}/models'\n",
        "        training_args = TrainingArguments(\n",
        "            logging_dir = f'./{model_name}_{ds_name}/logs',\n",
        "            output_dir= output_dir,\n",
        "            per_device_train_batch_size=per_device_train_batch_size,\n",
        "            per_device_eval_batch_size=per_device_eval_batch_size,\n",
        "            bf16=bf16,  # Use BF16 if available\n",
        "            fp16=fp16,\n",
        "            learning_rate=lr,\n",
        "            num_train_epochs=epochs,\n",
        "            max_steps = max_steps,\n",
        "            gradient_checkpointing=gradient_checkpointing,\n",
        "            optim=optim,\n",
        "            warmup_ratio=warmup_ratio,\n",
        "            weight_decay = weight_decay,\n",
        "            gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "            group_by_length=group_by_length,\n",
        "            # logging strategies\n",
        "            logging_strategy=\"steps\",\n",
        "            logging_steps=logging_steps,\n",
        "            #evaluation_strategy = evaluation_strategy,\n",
        "            save_strategy=save_strategy,\n",
        "            evaluation_strategy = save_strategy,\n",
        "            save_steps = save_steps,\n",
        "            eval_steps = eval_steps,\n",
        "            log_level = 'error',\n",
        "            hub_token=hf_token,\n",
        "            report_to='wandb' if wandb_token else None,\n",
        "            #dataloader_num_workers = dataloader_num_workers,\n",
        "            load_best_model_at_end=load_best_model_at_end,\n",
        "            save_total_limit = save_total_limit,\n",
        "            remove_unused_columns=False\n",
        "            #max_grad_norm=0.3\n",
        "        )\n",
        "\n",
        "        collator=sft_collator(tokenizer)\n",
        "\n",
        "\n",
        "        trainer = SFTTrainer(\n",
        "            model,\n",
        "            training_args,\n",
        "            max_seq_length = max_seq_length,\n",
        "            train_dataset = dataset['train'],\n",
        "            eval_dataset = dataset['validation'],\n",
        "            tokenizer=tokenizer,\n",
        "            formatting_func=formatting_prompts_func,\n",
        "            packing=False,\n",
        "            data_collator=collator\n",
        "            )\n",
        "\n",
        "    # Start training\n",
        "    trainer.train()\n",
        "\n",
        "    outputs=trainer.evaluate()\n",
        "    trainer.save_model(output_dir)\n",
        "\n",
        "\n",
        "    run.log({\"Performance-data\": wandb.Table(dataframe=\n",
        "                                             pd.DataFrame(outputs, index=[\"Performance\"]))})\n",
        "    model.push_to_hub('dhmeltzer/'+model_name)\n",
        "    tokenizer.push_to_hub('dhmeltzer/'+model_name)\n",
        "\n",
        "    trained_model_art=wandb.Artifact(model_name,type='model')\n",
        "    trained_model_art.metadata={\"hub_id\":'dhmeltzer/'+model_name}\n",
        "\n",
        "    #return trainer"
      ],
      "metadata": {
        "id": "HBDCkxCgrO8k"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "an8bLjYrOxeP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "hf_token = getpass()\n",
        "wandb_token = getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySv9n3A2-GXW",
        "outputId": "365ff90b-e2bd-4cfb-f38c-e597314e12a9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n",
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_function(model_id='meta-llama/Llama-2-7b-hf',\n",
        "                  dataset=ds_wiki,\n",
        "                  hf_token=hf_token,\n",
        "                  wandb_token=wandb_token,\n",
        "                  ds_name='wiki',\n",
        "                  per_device_train_batch_size=32,\n",
        "                  per_device_eval_batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509,
          "referenced_widgets": [
            "5f00b44bc76e4185b8f84247c4fd2426",
            "9498c248f44f4cc4bd25441e53a4226f",
            "c6f9a24e70334daebf0a0cebc2ec94af",
            "4d37888e063c4adea6598cfca6ebb2f9",
            "9ed763620d294e7d8528d99b0767dc04",
            "2d864fc54c094e908781b35675c32be2",
            "7f35c2861d99484aa33262e4f215990b",
            "f2c1491b0a2b49e8918ea4d5a9957a9d",
            "d569458da66f4efbbd8cc2b5555a6b56",
            "7abd4481af664acb9fe9840e03023a79",
            "03c7faf84c4e4c4eb9eed8d1e4fc6311"
          ]
        },
        "id": "lRxFccQk9y_q",
        "outputId": "f59dc291-2c09-4b1a-9c77-5492a2854150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f00b44bc76e4185b8f84247c4fd2426"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1714: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7 modules to quantize: ['down_proj', 'q_proj', 'k_proj', 'up_proj', 'gate_proj', 'o_proj', 'v_proj']\n",
            "trainable params: 159,907,840 || all params: 3,660,320,768 || trainable%: 4.368683788535114\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/drive/MyDrive/LLMs/Fine-tuning/SFT/wandb/run-20230811_142354-pk28tvgv</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ft-llmmm/SFT_training_dm/runs/pk28tvgv' target=\"_blank\">Llama-2-7b-hf_wiki_r_64_alpha_16_08.11.23-14.22.53</a></strong> to <a href='https://wandb.ai/ft-llmmm/SFT_training_dm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ft-llmmm/SFT_training_dm' target=\"_blank\">https://wandb.ai/ft-llmmm/SFT_training_dm</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ft-llmmm/SFT_training_dm/runs/pk28tvgv' target=\"_blank\">https://wandb.ai/ft-llmmm/SFT_training_dm/runs/pk28tvgv</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Llama-2-7b-hf_wiki_r_64_alpha_16_08.11.23-14.22.53</strong> at: <a href='https://wandb.ai/ft-llmmm/SFT_training_dm/runs/pk28tvgv' target=\"_blank\">https://wandb.ai/ft-llmmm/SFT_training_dm/runs/pk28tvgv</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230811_142354-pk28tvgv/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/drive/MyDrive/LLMs/Fine-tuning/SFT/wandb/run-20230811_142403-tzr04pll</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ft-llmmm/huggingface/runs/tzr04pll' target=\"_blank\">silver-bird-5</a></strong> to <a href='https://wandb.ai/ft-llmmm/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ft-llmmm/huggingface' target=\"_blank\">https://wandb.ai/ft-llmmm/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ft-llmmm/huggingface/runs/tzr04pll' target=\"_blank\">https://wandb.ai/ft-llmmm/huggingface/runs/tzr04pll</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13' max='234' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 13/234 02:11 < 44:04, 0.08 it/s, Epoch 0.05/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "Ii67UTsRrkOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_function(model_id='meta-llama/Llama-2-7b-hf',\n",
        "                  dataset=ds_wiki,\n",
        "                  hf_token=hf_token,\n",
        "                  wandb_token=wandb_token,\n",
        "                  ds_name='wiki',\n",
        "                  per_device_train_batch_size=50,\n",
        "                  per_device_eval_batch_size=100)"
      ],
      "metadata": {
        "id": "VpApKUmHrlAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "4HV_YocXuagg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments"
      ],
      "metadata": {
        "id": "25lKSBgIXPR-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## distil-GPT2"
      ],
      "metadata": {
        "id": "mGSB_REEevdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_training('distilgpt2',dataset=SFT_QA_dataset,prec=None,ds_name = 'combined')"
      ],
      "metadata": {
        "id": "0yItEUq59H11"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}